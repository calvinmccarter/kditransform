{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7dc01d-7ad0-44bc-96a3-75235d34f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "\n",
    "from GaussianMixtureSelect import GaussianMixtureSelect\n",
    "from KMeansSelect import KMeansSelect\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "from kdquantile import KDQuantileDiscretizer, KDDiscretizer\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf03c6a-eb23-4813-9217-989f646db0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(N, seed):\n",
    "    np.random.seed(seed)\n",
    "    a1 = np.random.normal(1, 0.75, size=int(0.55*N))\n",
    "    a2 = np.random.normal(4, 1, size=int(0.3*N))\n",
    "    a3 = np.random.uniform(0, 20, size=int(0.15*N))\n",
    "    a = np.sort(np.r_[a1, a2, a3])\n",
    "    a_labels = np.array([0]*int(0.55*N) + [1]*int(0.3*N) + [2]*int(0.15*N))\n",
    "    \n",
    "    b1 = np.random.normal(1, 0.5, size=int(0.45*N))\n",
    "    b2 = np.random.normal(4, 1, size=int(0.45*N))\n",
    "    b3 = np.random.uniform(0, 20, size=int(0.1*N))\n",
    "    b = np.sort(np.r_[b1, b2, b3])\n",
    "    b_labels = np.array([0]*int(0.45*N) + [1]*int(0.45*N) + [2]*int(0.1*N))\n",
    "    \n",
    "    c1 = np.random.normal(1, 0.5, size=int(0.67*N))\n",
    "    c2 = np.random.normal(4, 1, size=int(0.33*N))\n",
    "    c = np.sort(np.r_[c1, c2])\n",
    "    c_labels = np.array([0]*int(0.67*N) + [1]*int(0.33*N))\n",
    "      \n",
    "    dd1 = np.random.exponential(1, size=int(0.8*N))\n",
    "    dd2 = 10+np.random.exponential(4, size=int(0.2*N))\n",
    "    d = np.sort(np.r_[dd1, dd2])\n",
    "    d_labels = np.array([0]*int(0.8*N) + [1]*int(0.2*N))\n",
    "    \n",
    "    e1 = np.random.exponential(8, size=int(0.5*N))\n",
    "    e2 = 100 - np.random.exponential(5, size=int(0.5*N))\n",
    "    e = np.sort(np.r_[e1, e2])\n",
    "    e_labels = np.array([0]*int(0.5*N) + [1]*int(0.5*N))\n",
    "    \n",
    "    x_list = [a, b, c, d, e]\n",
    "    true_ks = [3, 3, 2, 2, 2]\n",
    "    true_labels = [a_labels, b_labels, c_labels, d_labels, e_labels]\n",
    "    return (x_list, true_ks, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13100ede-23df-4386-8f57-ccdad21481b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_list, true_ks, true_labels) = gen_data(N=500, seed=1)\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=4, ncols=len(x_list), sharex='col', sharey='row', figsize=(7,5))\n",
    "for curix, curx in enumerate(x_list):\n",
    "    method = KDQuantileDiscretizer(enable_predict_proba=True)\n",
    "    curx = curx.reshape(-1, 1)\n",
    "    method.fit(curx)\n",
    "    curp = method.kdqt_.transform(curx)\n",
    "    cury = method.transform(curx)\n",
    "    curz = method.predict_proba(curx)\n",
    "    axes[0,curix].hist(curx,30)\n",
    "    axes[1,curix].scatter(curx, curp, s=3)\n",
    "    axes[2,curix].scatter(curx,cury, s=3)\n",
    "    for k in range(method.kdd_.n_bins_[0]):\n",
    "        axes[3,curix].scatter(curx, curz[:,k], s=3)\n",
    "axes[0,0].set_ylabel('original data');\n",
    "axes[1,0].set_ylabel('KD-quantile \\n transform');\n",
    "axes[2,0].set_ylabel('predicted \\n discretized');\n",
    "axes[3,0].set_ylabel('predicted \\n probabilities');\n",
    "fig.patch.set_facecolor('white');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fef48-dea2-40e9-a22a-6bbc46535e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_list, true_ks, true_labels) = gen_data(N=500, seed=1)\n",
    "method_titles = [\n",
    "    \"Ground-truth\",\n",
    "    \"KMeans\", \n",
    "    \"GMM\",\n",
    "    \"Bayesian GMM\",\n",
    "    \"MeanShift\", \n",
    "    \"HDBSCAN\", \n",
    "    \"KDE Local Minima\", \n",
    "    \"KDQuantile\",\n",
    "]\n",
    "n_methods = len(method_titles)\n",
    "max_k = 8\n",
    "\n",
    "fig, big_axes = plt.subplots(figsize=(8, 8), nrows=n_methods, ncols=1, sharey=True)\n",
    "#fig.tight_layout()\n",
    "plt.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95, hspace=0.45)\n",
    "for row, big_ax in enumerate(big_axes, start=1):\n",
    "    big_ax.set_title(method_titles[row-1], fontsize=10)\n",
    "    big_ax.tick_params(\n",
    "        labelcolor=(1.,1.,1., 0.0), \n",
    "        top='off', bottom='off', left='off', right='off')\n",
    "    big_ax.spines[\"top\"].set_visible(False)\n",
    "    big_ax.spines[\"right\"].set_visible(False)\n",
    "    big_ax._frameon = False\n",
    "    big_ax.set_xticks([])\n",
    "    big_ax.set_yticks([])\n",
    "for curix, curx in enumerate(x_list):\n",
    "    true_k = true_ks[curix]\n",
    "    true_label = true_labels[curix]\n",
    "    mycurx = curx.reshape(-1, 1) # sklearn expects shape (N,1) not (N,)\n",
    "    methods = list(zip(\n",
    "        method_titles, [\n",
    "            None, \n",
    "            KMeansSelect(max_clusters=max_k),\n",
    "            GaussianMixtureSelect(max_components=max_k, criteria=\"BIC\"),\n",
    "            BayesianGaussianMixture(n_components=max_k),\n",
    "            MeanShift(bandwidth=estimate_bandwidth(mycurx, quantile=0.2, n_samples=500), bin_seeding=True),\n",
    "            HDBSCAN(min_cluster_size=5, cluster_selection_epsilon=0.5),\n",
    "            KDDiscretizer(), \n",
    "            KDQuantileDiscretizer()\n",
    "        ]\n",
    "    ))\n",
    "    for mix, minfo in enumerate(methods):\n",
    "        ax = fig.add_subplot(\n",
    "            n_methods, len(x_list), mix*len(x_list)+curix+1)\n",
    "        (method_name, method) = minfo\n",
    "        if method_name in (\"KDQuantile\", \"KDE Local Minima\"):\n",
    "            # My methods have the KBinsDiscretizer fit-transform API,\n",
    "            # not the sklearn.cluster fit-predict API.\n",
    "            method.fit(mycurx)\n",
    "            cury = method.transform(mycurx).flatten()\n",
    "        elif method_name == \"HDBSCAN\":\n",
    "            cury = method.fit_predict(mycurx)\n",
    "        elif method_name == \"Ground-truth\":\n",
    "            cury = true_label\n",
    "        else:\n",
    "            method.fit(mycurx)\n",
    "            cury = method.predict(mycurx)\n",
    "        k_list = list(np.unique(cury))     \n",
    "        clust_means = [(np.mean(curx[cury==k]), k) for k in k_list]\n",
    "        k_list_sorted = [k for _, k in sorted(clust_means, key=lambda _: _[0])]\n",
    "        curxclustered = [curx[cury==k] for k in k_list_sorted]\n",
    "        ax.hist(curxclustered, bins=20, stacked=True, edgecolor=\"white\", linewidth=0.01)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.tick_params(axis='y', which='major', labelsize=8, rotation=90, direction=\"in\", top=False, right=False, pad=0)\n",
    "        ax.tick_params(axis='x', which='major', labelsize=8, direction=\"in\")\n",
    "        if len(list(np.unique(cury))) == true_k:\n",
    "            tcolor = \"green\"\n",
    "        else:\n",
    "            tcolor = \"red\"\n",
    "        if method_name == \"Ground-truth\":\n",
    "            tcolor = \"black\"\n",
    "        ari = adjusted_rand_score(true_label, cury)        \n",
    "        ax.text(\n",
    "            0.63*ax.get_xlim()[1],\n",
    "            0.75*ax.get_ylim()[1],\n",
    "            #\"$\\hat{K}$=%i\\nARI=%.2f\" % (len(k_list), ari),\n",
    "            \"$\\hat{K}$=%i\" % len(k_list) if method_name != \"Ground-truth\" else \"$K$=%i\" % len(k_list),\n",
    "            color=tcolor, fontsize=8)\n",
    "        if mix != len(methods) - 1:\n",
    "            ax.set_xticks([])\n",
    "        else:\n",
    "            pass\n",
    "fig.patch.set_facecolor('white');\n",
    "plt.savefig(\"discretizing-synthetic-N500.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c3755-4615-4347-b96e-57f32617cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_random = 20\n",
    "N_list = [100, 200, 500, 1000, 2000, 5000]\n",
    "method_titles = [\n",
    "    \"KMeans\", \n",
    "    \"GMM\", \n",
    "    \"Bayesian GMM\",\n",
    "    \"MeanShift\", \n",
    "    \"HDBSCAN\", \n",
    "    \"KDQuantile\",\n",
    "]\n",
    "n_methods = len(method_titles)\n",
    "res_list = []\n",
    "# N, rix, {a, b, c, d, e, f}, method -> (Kcorrect, ARI)\n",
    "for N in N_list:\n",
    "    print(N)\n",
    "    for rix in range(n_random):\n",
    "        (x_list, true_ks, true_labels) = gen_data(N=N, seed=rix)\n",
    "        for curix, curx in enumerate(x_list):\n",
    "            true_k = true_ks[curix]\n",
    "            true_label = true_labels[curix]\n",
    "            mycurx = curx.reshape(-1, 1) # sklearn expects shape (N,1) not (N,)\n",
    "            methods = list(zip(\n",
    "                method_titles, [\n",
    "                    KMeansSelect(max_clusters=max_k),\n",
    "                    GaussianMixtureSelect(max_components=max_k, criteria=\"BIC\"),\n",
    "                    BayesianGaussianMixture(n_components=max_k),\n",
    "                    MeanShift(bandwidth=estimate_bandwidth(mycurx, quantile=0.2, n_samples=500), bin_seeding=True),\n",
    "                    HDBSCAN(min_cluster_size=5, cluster_selection_epsilon=0.5),\n",
    "                    KDQuantileDiscretizer(),\n",
    "                ]\n",
    "            ))\n",
    "            for mix, minfo in enumerate(methods):\n",
    "                (method_name, method) = minfo\n",
    "                if method_name in (\"KDE Local Minima\", \"KDQuantile\"):\n",
    "                    # My methods have the KBinsDiscretizer fit-transform API,\n",
    "                    # not the sklearn.cluster fit-predict API.\n",
    "                    method.fit(mycurx)\n",
    "                    cury = method.transform(mycurx).flatten()\n",
    "                elif method_name == \"HDBSCAN\":\n",
    "                    cury = method.fit_predict(mycurx)\n",
    "                elif method_name == \"Ground-truth\":\n",
    "                    cury = true_label\n",
    "                else:\n",
    "                    method.fit(mycurx)\n",
    "                    cury = method.predict(mycurx)\n",
    "                k_list = list(np.unique(cury))     \n",
    "                ari = adjusted_rand_score(true_label, cury)\n",
    "                res_list.append([rix, N, curix, method_name, len(k_list) == true_k, ari])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02196e6-5bf1-4688-882c-f3e8bd036961",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(data=res_list, columns=[\"rix\", \"N\", \"dataset\", \"method\", \"correctK\", \"ARI\"])\n",
    "b = a.groupby([\"N\", \"dataset\", \"method\"]).mean().reset_index()\n",
    "b = b[(b.method != \"Ground-truth\") &  (b.method != \"KDE Local Minima\")]\n",
    "fig, axes = plt.subplots(figsize=(8., 2.), ncols=5, sharey=True)\n",
    "fig.tight_layout();\n",
    "plt.subplots_adjust(top=0.98, right=0.99, wspace=0.08)\n",
    "for dataset in range(0, 5):\n",
    "    sns.lineplot(\n",
    "        data=b[b.dataset == dataset], \n",
    "        x=\"N\", y=\"ARI\", \n",
    "        hue=\"method\",\n",
    "        hue_order=method_titles,\n",
    "        style=\"method\",\n",
    "        style_order=method_titles,\n",
    "        ax=axes[dataset], markers=True, alpha=0.8, legend=False)\n",
    "    axes[dataset].set_xticks(N_list);\n",
    "    axes[dataset].set_xscale('log');\n",
    "    axes[dataset].tick_params(axis='y', which='major', labelsize=8, direction=\"in\", top=False, right=False, pad=0.12)\n",
    "    axes[dataset].tick_params(axis='x', which='major', labelsize=8, direction=\"in\")\n",
    "fig.savefig(\"discretizing-synthetic-ARI.pdf\");\n",
    "fig, axes = plt.subplots(figsize=(8., 2.), ncols=5, sharey=True)\n",
    "fig.tight_layout();\n",
    "plt.subplots_adjust(top=0.98, right=0.99, wspace=0.08)\n",
    "for dataset in range(0, 5):\n",
    "    sns.lineplot(\n",
    "        data=b[b.dataset == dataset], \n",
    "        x=\"N\", y=\"correctK\", \n",
    "        hue=\"method\",\n",
    "        hue_order=method_titles,\n",
    "        style=\"method\",\n",
    "        style_order=method_titles,\n",
    "        ax=axes[dataset], markers=True, alpha=0.8, \n",
    "        legend=dataset==4)\n",
    "    axes[dataset].set_xticks(N_list);\n",
    "    axes[dataset].set_ylabel(\"Accuracy ($\\hat{K} = K$)\");\n",
    "    axes[dataset].set_xscale('log');\n",
    "    axes[dataset].tick_params(axis='y', which='major', labelsize=8, direction=\"in\", top=False, right=False, pad=0.12)\n",
    "    axes[dataset].tick_params(axis='x', which='major', labelsize=8, direction=\"in\")\n",
    "sns.move_legend(axes[-1], \"upper right\", bbox_to_anchor=(1.0, -0.3), title=\"\")\n",
    "fig.savefig(\"discretizing-synthetic-accuracy.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad9609b-8537-4462-a5f2-52a96e48abad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
