{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb5776-9d2c-4a44-bd7e-40430b4b4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sklearn.datasets as skd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedShuffleSplit, \n",
    "    ShuffleSplit, KFold, StratifiedKFold,\n",
    ")\n",
    "\n",
    "import kditransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc6427-7109-453c-8174-81dfe3893206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wine():\n",
    "    columns = [\n",
    "        'Class label',\n",
    "        'Alcohol', 'Malic acid', 'Ash', 'Ash alcalinity',\n",
    "        'Magnesium', 'Total phenols', 'Flavanoids',\n",
    "        'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', \n",
    "        'Hue', 'OD280/OD315 of diluted wines', 'Proline'\n",
    "    ]\n",
    "    df = pd.io.parsers.read_csv('wine_data.csv', header=None)\n",
    "    X_wine = df.values[:,1:]\n",
    "    y_wine = df.values[:,0]\n",
    "    return X_wine, y_wine\n",
    "\n",
    "def get_iris():\n",
    "    df = sns.load_dataset('iris')\n",
    "    X_iris = df.values[:, 0:4]\n",
    "    y_iris = df.values[:, 4]\n",
    "    return X_iris, y_iris\n",
    "\n",
    "def get_penguins():\n",
    "    df = sns.load_dataset('penguins')\n",
    "    df = df.dropna()\n",
    "    columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "    X_penguins = df[columns].values\n",
    "    y_penguins = df[['species']].values.flatten()\n",
    "    return X_penguins, y_penguins\n",
    "\n",
    "def get_hawks():\n",
    "    columns = ['Wing', 'Weight', 'Culmen', 'Hallux', 'Tail']\n",
    "    # Downloaded from https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Hawks.csv\n",
    "    df = pd.io.parsers.read_csv('Hawks.csv')\n",
    "    df = df[columns+['Species']]\n",
    "    df = df.dropna()\n",
    "    X_hawks = df[columns].values\n",
    "    y_hawks = df[['Species']].values.flatten()\n",
    "    return X_hawks, y_hawks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb5ccb-c409-476b-83e2-12c1595507cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_random = 100\n",
    "n_alphas = 20\n",
    "n_splits = 30\n",
    "outer_test_size = 0.3\n",
    "inner_test_size = 0.3\n",
    "\n",
    "datasets = [\n",
    "    (\"wine\", get_wine()),\n",
    "    (\"iris\", get_iris()),\n",
    "    (\"penguins\", get_penguins()),\n",
    "    (\"hawks\", get_hawks()),\n",
    "]\n",
    "methods = [\n",
    "    (preprocessing.MinMaxScaler, 'min-max'),\n",
    "    (preprocessing.QuantileTransformer, 'quantile'),\n",
    "    (kditransform.KDITransformer, 'KD-integral'),\n",
    "]\n",
    "test_dict = {}\n",
    "alpha_dict = {}\n",
    "for dname, (X_all, y_all) in datasets:\n",
    "    test_dict[dname] = {}\n",
    "    alpha_dict[dname] = {}\n",
    "    for mname in [mname for _, mname in methods]+['KD-integral (bwf=CV)']:\n",
    "        test_dict[dname][mname] = {'pc': np.zeros(n_random)}\n",
    "    alpha_dict[dname] = {'pc': np.zeros((n_random, n_alphas))}\n",
    "\n",
    "for dname, (X_all, y_all) in datasets:\n",
    "    print(dname)\n",
    "    alphas = list(np.geomspace(0.1, 10, n_alphas))\n",
    "    random_states = list(range(n_random))\n",
    "    for rix, rstate in enumerate(random_states):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_all, y_all, test_size=outer_test_size, random_state=rstate)\n",
    "          \n",
    "        for preprocessor, pname in methods:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                prepper = preprocessor().fit(X_train)\n",
    "                X_train_prepped = prepper.transform(X_train)\n",
    "                X_test_prepped = prepper.transform(X_test)\n",
    "            # PCA + GaussianNB\n",
    "            pcaer = PCA(n_components=2).fit(X_train_prepped)\n",
    "            X_train_prepped_pc = pcaer.transform(X_train_prepped)\n",
    "            X_test_prepped_pc = pcaer.transform(X_test_prepped)\n",
    "            gnb_pc = GaussianNB().fit(X_train_prepped_pc, y_train)\n",
    "            acc_test_pc = metrics.accuracy_score(y_test, gnb_pc.predict(X_test_prepped_pc))\n",
    "            test_dict[dname][pname]['pc'][rix] = acc_test_pc\n",
    "    \n",
    "        sss = ShuffleSplit(n_splits=n_splits, test_size=inner_test_size, random_state=rstate)\n",
    "        acc_allsplits_pc = np.zeros((n_splits, len(alphas)))\n",
    "        for sssi, (trtr_index, trdev_index) in enumerate(sss.split(X_train, y_train)):\n",
    "            X_trtr = X_train[trtr_index, :]\n",
    "            y_trtr = y_train[trtr_index]\n",
    "            X_trdev = X_train[trdev_index, :]\n",
    "            y_trdev = y_train[trdev_index]\n",
    "            for aix, alpha in enumerate(alphas):\n",
    "                prepper = kditransform.KDITransformer(alpha=alpha).fit(X_train)\n",
    "                X_train_prepped = prepper.transform(X_train)\n",
    "                X_trtr_prepped = prepper.transform(X_trtr)\n",
    "                X_trdev_prepped = prepper.transform(X_trdev)\n",
    "                pcaer = PCA(n_components=2).fit(X_train_prepped)\n",
    "                X_trtr_prepped_pc = pcaer.transform(X_trtr_prepped)\n",
    "                X_trdev_prepped_pc = pcaer.transform(X_trdev_prepped)\n",
    "                gnb_pc = GaussianNB().fit(X_trtr_prepped_pc, y_trtr)\n",
    "                acc_trdev_pc = metrics.accuracy_score(y_trdev, gnb_pc.predict(X_trdev_prepped_pc))\n",
    "                acc_allsplits_pc[sssi, aix] = acc_trdev_pc\n",
    "        acc_splits_pc = np.mean(acc_allsplits_pc, axis=0)\n",
    "    \n",
    "        for aix, alpha in enumerate(alphas):\n",
    "            prepper = kditransform.KDITransformer(alpha=alpha).fit(X_train)\n",
    "            X_train_prepped = prepper.transform(X_train)\n",
    "            X_test_prepped = prepper.transform(X_test)\n",
    "            pcaer = PCA(n_components=2).fit(X_train_prepped)\n",
    "            X_train_prepped_pc = pcaer.transform(X_train_prepped)\n",
    "            X_test_prepped_pc = pcaer.transform(X_test_prepped)\n",
    "            gnb_pc = GaussianNB().fit(X_train_prepped_pc, y_train)\n",
    "            acc_test_pc = metrics.accuracy_score(y_test, gnb_pc.predict(X_test_prepped_pc))\n",
    "            alpha_dict[dname]['pc'][rix, aix] = acc_test_pc\n",
    "            if aix == np.argmax(acc_splits_pc):\n",
    "                test_dict[dname]['KD-integral (bwf=CV)']['pc'][rix] = acc_test_pc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65ffc4-ec37-4360-88af-a914b2304ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dname in list(test_dict.keys()):\n",
    "    markers = itertools.cycle(('^', 's', '*', 'o', '.'))\n",
    "    colors = itertools.cycle(('red', 'blue', 'purple', 'magenta', 'green')) \n",
    "    alph = np.array([np.min(alphas), np.max(alphas)]);\n",
    "    fig = plt.figure(figsize=(4,3), dpi=150)\n",
    "    for pname in list(test_dict[dname].keys()):\n",
    "        tmean = test_dict[dname][pname]['pc'].mean()\n",
    "        tstd = np.std(test_dict[dname][pname]['pc'], ddof=1) / np.sqrt(n_random)\n",
    "        (_, caps, _) = plt.errorbar(\n",
    "            alph, tmean*np.ones(2), yerr=tstd*np.ones(2), \n",
    "            marker=next(markers), c = next(colors), markersize=10, alpha=0.5, capsize=4,\n",
    "            label=f'{pname} (bwf=1)' if pname=='KD-integral' else pname);\n",
    "        for cap in caps:\n",
    "            cap.set_markeredgewidth(2)\n",
    "    amean = alpha_dict[dname]['pc'].mean(axis=0)\n",
    "    astd = np.std(alpha_dict[dname]['pc'], axis=0, ddof=1) / np.sqrt(n_random)\n",
    "    plt.errorbar(\n",
    "        alphas, amean, yerr=astd,\n",
    "        marker=next(markers), c=next(colors), markersize=2, alpha=0.5, capsize=2,\n",
    "        label='KD-integral');\n",
    "    plt.xlabel('KD-integral bandwidth factor');\n",
    "    plt.ylabel('Accuracy');\n",
    "    plt.xscale('log');\n",
    "    plt.xlim(np.min(alphas), np.max(alphas));\n",
    "    fig.savefig(f'Accuracy-vs-bwf-{dname}-pca-nolegend.pdf', bbox_inches='tight')\n",
    "    plt.legend(loc='lower center');\n",
    "    fig.savefig(f'Accuracy-vs-bwf-{dname}-pca.pdf', bbox_inches='tight')\n",
    "    plt.title(f'{dname} PCA');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb33a93-addb-4ab3-b003-366287dca527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "with open(\"ansur_test_dict.pickle\", \"wb\") as f:\n",
    "    pickle.dump(test_dict, f)\n",
    "with open(\"ansur_alpha_dict.pickle\", \"wb\") as f:\n",
    "    pickle.dump(alpha_dict, f)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390a330-18b6-4947-bfbd-2dbd82ac9261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
